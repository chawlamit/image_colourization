{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from PIL import Image\n",
    "import json\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_from_url(url):\n",
    "    \"\"\"\n",
    "    returns PIL Image object from response\n",
    "    :param url:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    img_loc = Image.open(BytesIO(response.content))\n",
    "    return img_loc\n",
    "\n",
    "\n",
    "def rgbToGray(rgb):\n",
    "    \"\"\"\n",
    "    :param rgb: 1D np array consisting of RGB values of the pixel\n",
    "    :return: gray = 0.21r + 0.72g  + 0.07b\n",
    "    \"\"\"\n",
    "    return np.dot(np.array([0.21, 0.72, 0.07]), rgb)\n",
    "\n",
    "\n",
    "def generate_data_set_from_image(image: Image, x_data, y_data, window_shape = (3, 3)):\n",
    "    \"\"\"\n",
    "    Window dimensions are always assumed to be odd, i.e. we always have a middle element\n",
    "    \"\"\"\n",
    "    arr = np.asarray(image)\n",
    "    n, m = arr.shape[0], arr.shape[1]\n",
    "\n",
    "    # base case: image must be larger than the window size\n",
    "    if n < window_shape[0] or m < window_shape[1]:\n",
    "        return None\n",
    "\n",
    "    row_margin = window_shape[0] // 2\n",
    "    col_margin = window_shape[1] // 2\n",
    "    for i in range(0 + row_margin, n - row_margin):\n",
    "        for j in range(0 + col_margin, m - col_margin):\n",
    "            data_pt = []\n",
    "            for x in range(i - row_margin, i + row_margin + 1):\n",
    "                for y in range(j - col_margin, j + col_margin + 1):\n",
    "                    rgb = arr[x, y, ] / 255\n",
    "                    # middle element of filter, to be used as output\n",
    "                    if x == i and y == j:\n",
    "                        y_data.append(rgb)\n",
    "                    data_pt.append(rgbToGray(rgb) / 255)\n",
    "            x_data.append(np.array(data_pt))\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Img: 27950322870_771d53a6e2.jpg\n",
      "Processing Img: 27927622835_32b1427ea7.jpg\n",
      "Processing Img: 22888085296_81b4b91bb0.jpg\n",
      "Processing Img: 25386994904_7e78d93464.jpg\n",
      "Processing Img: 3765844098_5a00513949.jpg\n",
      "Processing Img: 8391674818_19b47906b4.jpg\n",
      "Processing Img: 26237203136_59d280b8e4.jpg\n",
      "Processing Img: 28063736211_9321570bbd.jpg\n",
      "Processing Img: 26601819584_77220c0eb5.jpg\n",
      "Processing Img: 8023983958_567e126058.jpg\n",
      "Processing Img: 16479227725_ac8b713757.jpg\n",
      "Generating data from 11 images\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "window_shape = (5, 5)\n",
    "row_margin = window_shape[0] // 2\n",
    "col_margin = window_shape[1] // 2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    with open('dataset/forest_photos_info.json', 'r') as fo:\n",
    "        dataset = json.loads(fo.read())\n",
    "        for i, image_key in enumerate(oceans):\n",
    "            print(f\"Processing Img: {image_key}\")\n",
    "            img = get_image_from_url(dataset[image_key]['url'])\n",
    "            # img.show()\n",
    "            # input()\n",
    "            generate_data_set_from_image(img, x_data, y_data, window_shape)\n",
    "            if i == 10:\n",
    "                print(f\"Generating data from {i+1} images\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, input_dim=window_shape[0] * window_shape[1], activation='sigmoid'))\n",
    "model.add(Dense(15, activation='sigmoid'))\n",
    "model.add(Dense(3))\n",
    "          \n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1653216/1835868 [==========================>...] - ETA: 8s - loss: 0.0213 - accuracy: 0.6448"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(x_data), np.array(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Let's try to predict the output image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1299455_fb3636f431.jpg',\n",
       " '7460265344_f3a60b2a6d.jpg',\n",
       " '5660119953_229aac8e2d.jpg',\n",
       " '14759591072_a6bfaa05ac.jpg',\n",
       " '26911681691_7b7494d1bc.jpg',\n",
       " '7793140654_4f8abfb57c.jpg',\n",
       " '13193044613_345bf475bd.jpg',\n",
       " '4692542180_71ebaa29a7.jpg',\n",
       " '4124025640_59d557c75a.jpg']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.keys())[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image\n",
    "img_str = '4124025640_59d557c75a.jpg'\n",
    "img = get_image_from_url(dataset[img_str]['url'])\n",
    "np_img = np.asarray(img)\n",
    "img.show()\n",
    "\n",
    "# gray scale\n",
    "gray_img = 0.21*np_img[:, :, 0] + 0.72*np_img[:, :, 1] + 0.07*np_img[:, :, 2]\n",
    "gray_img = Image.fromarray(gray_img.astype(np.uint8))\n",
    "gray_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(371, 496, 3)\n"
     ]
    }
   ],
   "source": [
    "out = np.zeros(shape)\n",
    "x_test, y_test = [], []\n",
    "\n",
    "generate_data_set_from_image(img, x_test, y_test, window_shape)\n",
    "out = model.predict(np.array(x_test))\n",
    "out = out * 255\n",
    "out = out.reshape(np_img.shape - np.array([2*row_margin, 2*col_margin, 0]))\n",
    "print(out.shape)\n",
    "\n",
    "out_img = Image.fromarray(out.astype(np.uint8))\n",
    "out_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### end #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
